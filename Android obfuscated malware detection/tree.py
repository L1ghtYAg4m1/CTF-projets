import numpy as np
import pandas as pd
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import LabelEncoder

# Load the dataset containing features
df = pd.read_csv('features.csv')

# Check for non-numeric columns and convert them to numeric
for column in df.columns:
    if df[column].dtype == 'object':
        encoder = LabelEncoder()
        df[column] = encoder.fit_transform(df[column])

# Handle missing values by filling NaN with 0
df = df.fillna(0)

# Load the API calls
with open('mixed_dataset/all_api_calls.txt') as all_api_calls_file:
    all_api_calls = [line.strip() for line in all_api_calls_file]

# Initialize the target list (0 for benign, 1 for malware)
target = []
with open('training_file_index', 'r') as indexed_file:
    for row in indexed_file.readlines():
        components = row.split('-')
        name = components[0]
        if 'benign' in name:
            target.append(0)
        else:
            target.append(1)

# Ensure target is a numpy array
target = np.array(target)

# Train the classifier on the dataset
clf = ExtraTreesClassifier()
clf = clf.fit(df, target)

# Select important features
model = SelectFromModel(clf, prefit=True)
X_new = model.transform(df)

# Output selected features
print(X_new.shape)
selected_features = model.get_support(indices=True)

# Check the lengths of the lists to avoid the IndexError
print("Length of all_api_calls:", len(all_api_calls))
print("Number of selected features:", len(selected_features))

# Adjusting selected_features to avoid going out of bounds
max_index = len(all_api_calls)  # Maximum valid index for all_api_calls

with open('tree.txt', 'w') as f:
    for a in selected_features:
        if a < max_index:  # Ensure the index is within bounds
            f.write(all_api_calls[a] + "\n")
        else:
            print(f"Warning: Skipping feature index {a} as it exceeds all_api_calls length.")
